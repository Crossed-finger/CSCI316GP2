{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('GA2Datasets/UNSW_NB15_training-set.csv')\n",
    "test_df = pd.read_csv('GA2Datasets/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom pipeline for dat pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "class PreProcessPipeline:\n",
    "    def __init__(self, label_encode = True, process_label = 'Binary', smote = False):\n",
    "        self.label_encode = label_encode\n",
    "        self.process_label = process_label\n",
    "        self.smote = smote\n",
    "    \n",
    "    def fit(self):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.copy()\n",
    "        if self.label_encode:\n",
    "            columns = ['proto', 'service', 'state', 'attack_cat']\n",
    "            for column in columns:\n",
    "                unique_values = df[column].unique()\n",
    "                mapping = {value: index for index, value in enumerate(unique_values)}\n",
    "                df[column] = df[column].map(mapping)\n",
    "\n",
    "        if self.process_label == 'Binary':\n",
    "            df.drop('attack_cat', axis=1, inplace=True)\n",
    "        else:             \n",
    "            df['attack_cat'], df['label'] = df['label'], df['attack_cat']\n",
    "            df.drop('attack_cat', axis=1, inplace=True)   \n",
    "\n",
    "        if self.smote:\n",
    "            # Separate features and labels\n",
    "            X = df.drop('label', axis=1)\n",
    "            y = df['label']\n",
    "\n",
    "            # Apply SMOTE for oversampling\n",
    "            smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "            X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "            # Convert NumPy arrays back to Pandas DataFrames\n",
    "            X_resampled_df = pd.DataFrame(data=X_resampled, columns=X.columns)\n",
    "            y_resampled_df = pd.DataFrame(data=y_resampled, columns=['label'])\n",
    "\n",
    "            # Concatenate the features and label columns into a single DataFrame\n",
    "            df = pd.concat([X_resampled_df, y_resampled_df], axis=1)   \n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_train = PreProcessPipeline(label_encode=True, process_label='Binary')\n",
    "pipeline_test = PreProcessPipeline(label_encode=True, process_label='Binary')\n",
    "train_df = pipeline_train.transform(train_df)\n",
    "test_df = pipeline_test.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure with subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Plot countplot for column1\n",
    "sns.countplot(data=train_df, x='label', palette=\"Set1\", ax=axes[0])\n",
    "axes[0].set_title(\"Label Plot for train df\")\n",
    "axes[0].set_xlabel(\"Column 1\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "# Plot countplot for column2\n",
    "sns.countplot(data=test_df, x='label', palette=\"Set2\", ax=axes[1])\n",
    "axes[1].set_title(\"Label Plot for test df\")\n",
    "axes[1].set_xlabel(\"Column 2\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train_df, test_df])\n",
    "shuffled_df = combined_df.sample(frac=1, random_state=42)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(shuffled_df) * split_ratio)\n",
    "\n",
    "train_df = shuffled_df[:split_index]\n",
    "test_df = shuffled_df[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams[\"figure.figsize\"]=(20,22)\n",
    "train_df.hist()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize - Correlation matrix\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = train_df.corr()\n",
    "\n",
    "# Select the correlation values with 'label', label here means attack_cat\n",
    "target_corr = corr_matrix['label']\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the feature ranking in corr order \n",
    "\n",
    "# Calculate the absolute correlation values with the 'label'\n",
    "target_corr_abs = corr_matrix['label'].abs()\n",
    "\n",
    "# Sort the correlation values in descending order\n",
    "sorted_corr = target_corr_abs.sort_values(ascending=False)\n",
    "\n",
    "# Print the sorted correlation values and their corresponding attributes\n",
    "for attribute, correlation in target_corr_abs.items():\n",
    "    print(f\"{attribute}: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"CSCI316GP2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparktrain_df = spark.createDataFrame(train_df)\n",
    "sparktest_df = spark.createDataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Khanh Nguyen\n",
    "Name: PySpark Dataframe Pipeline\n",
    "Description:\n",
    "    This class is used to create a pipeline for PySpark dataframe, accept 2 boolean parameter: smote & standardize.\n",
    "    Features \n",
    "        (Default)\n",
    "        - Resample: Resample the dataframe\n",
    "        - Vectorize: Vectorize the dataframe\n",
    "        (activate by setting the parameter to True):\n",
    "        - SMOTE: Oversampling the minority class\n",
    "        - Standardize: Standardize the dataframe using z-score\n",
    "'''\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "class SparkDFPipeline:\n",
    "    def __init__(self, standardize=False):\n",
    "        self.standardize = standardize\n",
    "    \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, train_df, test_df):      \n",
    "        if self.standardize:\n",
    "            # Standardize the df\n",
    "\n",
    "            # Resample the df\n",
    "            num_partitions = 500\n",
    "            repartitioned_df = train_df.repartition(num_partitions)\n",
    "\n",
    "            exclude = ['proto', 'service', 'state']\n",
    "            input_columns = train_df.columns[:-1]\n",
    "            selected_columns = [col for col in input_columns if col not in exclude]\n",
    "            # Vectorize the df\n",
    "            assembler = VectorAssembler(inputCols=selected_columns, outputCol='features')\n",
    "            train_df = assembler.transform(repartitioned_df)\n",
    "            test_df = assembler.transform(test_df)\n",
    "\n",
    "            # Standardize the df\n",
    "            scaler = StandardScaler(inputCol='features', outputCol='scaled_features', withStd=True, withMean=True)\n",
    "            scaler_model = scaler.fit(train_df)\n",
    "            train_df = scaler_model.transform(train_df)\n",
    "\n",
    "            scaler_model = scaler.fit(test_df)\n",
    "            test_df = scaler_model.transform(test_df)\n",
    "            test_df = test_df.drop('features')\n",
    "            train_df = train_df.drop('features')\n",
    "            \n",
    "            # put back the categorical columns\n",
    "            input_cols = ['scaled_features', 'proto', 'service', 'state']\n",
    "            output_col = \"features\"\n",
    "            assembler1 = VectorAssembler(inputCols=input_cols, outputCol=output_col)\n",
    "            train_df = assembler1.transform(train_df)\n",
    "            test_df = assembler1.transform(test_df)\n",
    "\n",
    "            # return result\n",
    "            test_df = test_df.select('features', 'label')\n",
    "            train_df = train_df.select('features', 'label')\n",
    "        else:\n",
    "            # Normal vectorize df\n",
    "            num_partitions = 500\n",
    "            repartitioned_df = train_df.repartition(num_partitions)\n",
    "            input_columns = train_df.columns[:-1]\n",
    "            assembler = VectorAssembler(inputCols=input_columns, outputCol='features')\n",
    "            train_df = assembler.transform(repartitioned_df)\n",
    "            train_df = train_df.select('features', 'label')\n",
    "            test_df = assembler.transform(test_df)\n",
    "              \n",
    "        return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = SparkDFPipeline(standardize=True)\n",
    "train, test = pipeline.transform(sparktrain_df, sparktest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM model\n",
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=100) \n",
    "svm_model = svm.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction \n",
    "\n",
    "predictions = svm_model.transform(test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create an evaluator for accuracy\n",
    "roc_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "roc_score = roc_evaluator.evaluate(predictions)\n",
    "print(\"Area under ROC = %g\" % roc_score)\n",
    "\n",
    "# Create an evaluator for f1 score\n",
    "pr_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "pr_score = pr_evaluator.evaluate(predictions)\n",
    "print(\"Area under PR = %g\" % pr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=100)\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.maxIter, [10, 50, 100]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator for model selection\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Create CrossValidator\n",
    "cross_val = CrossValidator(estimator=svm,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=evaluator,\n",
    "                           numFolds=5)  # Number of folds for cross-validation\n",
    "\n",
    "# Fit CrossValidator on train data\n",
    "cv_model = cross_val.fit(train)\n",
    "\n",
    "# Get the best LinearSVC model from the cross-validation\n",
    "best_svm_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction \n",
    "\n",
    "predictions = best_svm_model.transform(test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Create an evaluator for accuracy\n",
    "roc_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "roc_score = roc_evaluator.evaluate(predictions)\n",
    "print(\"Area under ROC = %g\" % roc_score)\n",
    "\n",
    "# Create an evaluator for f1 score\n",
    "pr_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\")\n",
    "pr_score = pr_evaluator.evaluate(predictions)\n",
    "print(\"Area under PR = %g\" % pr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
